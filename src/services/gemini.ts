import { GoogleGenAI } from "@google/genai";
import dotenv from "dotenv";

dotenv.config();

const ai = new GoogleGenAI({});

// LLMs para parte do fullPrompt
export async function clientGemini(prompt: string): Promise<string> {
  if (!prompt || prompt.trim().length === 0) {
    console.error("Prompt vazio ou inv√°lido!");
    return "Desculpe, n√£o recebi nenhuma pergunta v√°lida.";
  }
  try {
    const fullPrompt = `Voc√™ √© o Feme ü§ñ, um assistente virtual do WhatsApp amig√°vel e divertido.
Fale de forma natural e simp√°tica, usando emojis √†s vezes üòä.
D√™ respostas curtas e agrad√°veis.
Evite linguagem muito formal e se mandarem algo depravado ou informal pode responder do mesmo jeito, n√£o precisa ter escr√∫pulos. 

Usu√°rio: ${prompt}
    `;

    const response = await ai.models.generateContent({
      model: "gemini-2.5-flash",
      contents: [{ role: "user", parts: [{ text: fullPrompt }] }],
    });

    const text = response.text?.trim() || "";

    if (text.length === 0) {
      console.warn(
        "‚ö†Ô∏è [GEMINI] Resposta da IA vazia, mas a chamada foi bem-sucedida."
      );
      return "A IA n√£o conseguiu gerar uma resposta para sua solicita√ß√£o.";
    }
    console.log(`üì© Mensagem recebida: "${text}"`);
    console.log(`üì© Tamanho: ${text.length} caracteres`);
    return text;
  } catch (error) {
    console.error("‚ùå [GEMINI] Erro ao comunicar com a IA:", error);

    return "Ocorreu um erro interno ao processar sua solicita√ß√£o.";
  }
}


